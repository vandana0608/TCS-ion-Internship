{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "EmotionDetectionmainforNaives.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZSXw5NMBDATy",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 139
        },
        "outputId": "e2092f06-6b8b-49ce-ad21-1f95a3edfe94"
      },
      "source": [
        "import nltk\n",
        "nltk.download('punkt')\n",
        "nltk.download('averaged_perceptron_tagger')"
      ],
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
            "[nltk_data]       date!\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 53
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F3f0a0NjAzqh",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 280
        },
        "outputId": "d7330282-f57c-4130-eebe-497e75fb3798"
      },
      "source": [
        "!pip install smart_open\n",
        "from __future__ import division\n",
        "import nltk \n",
        "import re\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.stem import *\n",
        "from textblob.classifiers import NaiveBayesClassifier\n",
        "from sklearn.model_selection import KFold\n",
        "from nltk.classify.naivebayes import NaiveBayesClassifier\n",
        "from gensim import corpora, models, similarities\n",
        "from nltk.corpus import wordnet as wn\n",
        "from smart_open import open"
      ],
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: smart_open in /usr/local/lib/python3.6/dist-packages (2.0.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from smart_open) (2.23.0)\n",
            "Requirement already satisfied: boto in /usr/local/lib/python3.6/dist-packages (from smart_open) (2.49.0)\n",
            "Requirement already satisfied: boto3 in /usr/local/lib/python3.6/dist-packages (from smart_open) (1.14.9)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->smart_open) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->smart_open) (2.9)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->smart_open) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->smart_open) (2020.6.20)\n",
            "Requirement already satisfied: s3transfer<0.4.0,>=0.3.0 in /usr/local/lib/python3.6/dist-packages (from boto3->smart_open) (0.3.3)\n",
            "Requirement already satisfied: jmespath<1.0.0,>=0.7.1 in /usr/local/lib/python3.6/dist-packages (from boto3->smart_open) (0.10.0)\n",
            "Requirement already satisfied: botocore<1.18.0,>=1.17.9 in /usr/local/lib/python3.6/dist-packages (from boto3->smart_open) (1.17.9)\n",
            "Requirement already satisfied: docutils<0.16,>=0.10 in /usr/local/lib/python3.6/dist-packages (from botocore<1.18.0,>=1.17.9->boto3->smart_open) (0.15.2)\n",
            "Requirement already satisfied: python-dateutil<3.0.0,>=2.1 in /usr/local/lib/python3.6/dist-packages (from botocore<1.18.0,>=1.17.9->boto3->smart_open) (2.8.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.6/dist-packages (from python-dateutil<3.0.0,>=2.1->botocore<1.18.0,>=1.17.9->boto3->smart_open) (1.12.0)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vdo5DcGJB-_r",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Read dataset ISEAR.csv\n",
        "Data = pd.read_csv('ISEAR.csv',header=None)"
      ],
      "execution_count": 55,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UrxTVktGCdj8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Emotions to be detected\n",
        "emotion_labels = ['joy', 'fear', 'anger', 'sadness', 'disgust', 'shame', 'guilt']"
      ],
      "execution_count": 56,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sQ8o5eHwCgmx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Negation words\n",
        "negation_words = ['not', 'neither', 'nor', 'but', 'however', 'although', 'nonetheless', 'despite', 'except', 'even though', 'yet']"
      ],
      "execution_count": 57,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5BLc5s_mCjHw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Returns a list of all corresponding class labels\n",
        "def class_labels(emotions):\n",
        "    labels = []\n",
        "    labelset = []\n",
        "    exclude = []\n",
        "    for i in range(len(emotions)):\n",
        "#         labels.append(e)\n",
        "#         labelset.append([e])\n",
        "        if emotions[i] not in ['shame','guilt']:\n",
        "            labels.append(e)\n",
        "            labelset.append([e])\n",
        "        else:\n",
        "            exclude.append(i)\n",
        "    return labels, labelset, exclude"
      ],
      "execution_count": 58,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qAFrWtC1CmG2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Removes unnecessary characters from sentences\n",
        "def removal(sentences):\n",
        "    sentence_list = []\n",
        "    count = 0\n",
        "#     for sen in sentences:\n",
        "#         count += 1\n",
        "#         print count\n",
        "#         print sen\n",
        "#         print type(sen)\n",
        "    s = nltk.word_tokenize(sentences)\n",
        "    characters = [\"รก\", \"\\xc3\", \"\\xa1\", \"\\n\", \",\", \".\", \"[\", \"]\", \"\"]\n",
        "    l = []\n",
        "    for t in s:\n",
        "        if t not in characters:\n",
        "            l.append(t)\n",
        "    return l\n",
        "#     new = ' '.join([i for i in s if not [e for e in characters if e in i]])\n",
        "#     print new\n",
        "#     sentence_list.append(new)\n",
        "#     return sentence_list"
      ],
      "execution_count": 59,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5sI_bhKvCpIW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#POS-TAGGER, returns NAVA words\n",
        "def pos_tag(sentences):\n",
        "    tags = [] #have the pos tag included\n",
        "    nava_sen = []\n",
        "    pt = nltk.pos_tag(sentences)\n",
        "#     for s in sentences:\n",
        "#     s_token = nltk.word_tokenize(sentences)\n",
        "#     pt = nltk.pos_tag(s_token)\n",
        "    nava = []\n",
        "    nava_words = []\n",
        "    for t in pt:\n",
        "        if t[1].startswith('NN') or t[1].startswith('JJ') or t[1].startswith('VB') or t[1].startswith('RB'):\n",
        "            nava.append(t)\n",
        "            nava_words.append(t[0])\n",
        "    return nava, nava_words\n",
        "#     tags.append(nava)\n",
        "#     nava_sen.append(nava_words)\n",
        "#     return tags, nava_sen"
      ],
      "execution_count": 60,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-EoOf6u0Crm4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Performs stemming\n",
        "def stemming(sentences):\n",
        "    sentence_list = []\n",
        "    sen_string = []\n",
        "    sen_token = []\n",
        "    stemmer = PorterStemmer()\n",
        "    i = 0\n",
        "#     for sen in sentences:\n",
        "#         print i,\n",
        "    i += 1\n",
        "    st = \"\"\n",
        "    for word in sentences:\n",
        "        word_l = word.lower()\n",
        "        if len(word_l) >= 3:\n",
        "            st += stemmer.stem(word_l) + \" \"\n",
        "    sen_string.append(st)\n",
        "    w_set = nltk.word_tokenize(st)\n",
        "    sen_token.append(w_set)\n",
        "    w_text = nltk.Text(w_set)\n",
        "    sentence_list.append(w_text)\n",
        "    return w_text, st, w_set\n",
        "#     return sentence_list, sen_string, sen_token"
      ],
      "execution_count": 61,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oY17jbGKCt1L",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Write to file\n",
        "def write_to_file(filename, text):\n",
        "    o = open(filename,'w')\n",
        "    o.write(str(text))\n",
        "    o.close()"
      ],
      "execution_count": 62,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IrmsbwHuCw8t",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Creating the dataframe\n",
        "def create_frame(Data):\n",
        "    labels = []\n",
        "#     sentences = []\n",
        "#     sen_string = []\n",
        "#     sen_token =[]\n",
        "    sen = []\n",
        "    sen_s = []\n",
        "    sen_t = []\n",
        "    labelset = []\n",
        "    for i in range(len(Data)):\n",
        "        if i >= 0:\n",
        "#             print i,\n",
        "            emotion = Data[0][i]\n",
        "            sit = Data[1][i]\n",
        "#             if emotion not in ['shame', 'guilt']:\n",
        "            labels.append(emotion)\n",
        "            labelset.append([emotion])\n",
        "            sent = removal(sit)\n",
        "            nava, sent_pt = pos_tag(sent)\n",
        "            sentences, sen_string, sen_token = stemming(sent_pt)\n",
        "            sen.append(sentences)\n",
        "            sen_s.append(sen_string)\n",
        "            sen_t.append(sen_token)\n",
        "#     labels, labelset, exclude = class_labels(emotions[1:])\n",
        "#     sent = removal(sit[1:], exclude)\n",
        "#     nava, sent_pt = pos_tag(sent)\n",
        "#     sentences, sen_string, sen_token = stemming(sent_pt)\n",
        "    frame = pd.DataFrame({0 : labels,\n",
        "                          1 : sen,\n",
        "                          2 : sen_s,\n",
        "                          3 : sen_t,\n",
        "                          4 : labelset})\n",
        "    return frame, sen_t, labels, sen_s"
      ],
      "execution_count": 63,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sIXCOzDRDDqy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Calling the create_frame function\n",
        "c, st, labels, senten = create_frame(Data)"
      ],
      "execution_count": 64,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vQNKNsEODN7L",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 589
        },
        "outputId": "3ecfc8ff-417a-436d-de9e-c7216324b02d"
      },
      "source": [
        "#Display of frames with classification of words on emotions labels\n",
        "c"
      ],
      "execution_count": 65,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "      <th>3</th>\n",
              "      <th>4</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>joy</td>\n",
              "      <td>(day, feel, close, partner, other, friend, fee...</td>\n",
              "      <td>day feel close partner other friend feel peac ...</td>\n",
              "      <td>[day, feel, close, partner, other, friend, fee...</td>\n",
              "      <td>[joy]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>fear</td>\n",
              "      <td>(time, imagin, someon, love, contact, seriou, ...</td>\n",
              "      <td>time imagin someon love contact seriou ill eve...</td>\n",
              "      <td>[time, imagin, someon, love, contact, seriou, ...</td>\n",
              "      <td>[fear]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>anger</td>\n",
              "      <td>(had, been, obvious, unjustli, treat, had, pos...</td>\n",
              "      <td>had been obvious unjustli treat had possibl el...</td>\n",
              "      <td>[had, been, obvious, unjustli, treat, had, pos...</td>\n",
              "      <td>[anger]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>sadness</td>\n",
              "      <td>(think, short, time, live, relat, period, life...</td>\n",
              "      <td>think short time live relat period life think ...</td>\n",
              "      <td>[think, short, time, live, relat, period, life...</td>\n",
              "      <td>[sadness]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>disgust</td>\n",
              "      <td>(gather, found, involuntarili, sit, next, peop...</td>\n",
              "      <td>gather found involuntarili sit next peopl expr...</td>\n",
              "      <td>[gather, found, involuntarili, sit, next, peop...</td>\n",
              "      <td>[disgust]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7511</th>\n",
              "      <td>shame</td>\n",
              "      <td>(year, back, someon, invit, tutor, grand-daugh...</td>\n",
              "      <td>year back someon invit tutor grand-daught gran...</td>\n",
              "      <td>[year, back, someon, invit, tutor, grand-daugh...</td>\n",
              "      <td>[shame]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7512</th>\n",
              "      <td>shame</td>\n",
              "      <td>(had, taken, respons, someth, had, prepar, how...</td>\n",
              "      <td>had taken respons someth had prepar howev fail...</td>\n",
              "      <td>[had, taken, respons, someth, had, prepar, how...</td>\n",
              "      <td>[shame]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7513</th>\n",
              "      <td>fear</td>\n",
              "      <td>(wa, home, heard, loud, sound, spit, door, tho...</td>\n",
              "      <td>wa home heard loud sound spit door thought fam...</td>\n",
              "      <td>[wa, home, heard, loud, sound, spit, door, tho...</td>\n",
              "      <td>[fear]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7514</th>\n",
              "      <td>guilt</td>\n",
              "      <td>(did, not, homework, teacher, had, ask, wa, sc...</td>\n",
              "      <td>did not homework teacher had ask wa scold immedi</td>\n",
              "      <td>[did, not, homework, teacher, had, ask, wa, sc...</td>\n",
              "      <td>[guilt]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7515</th>\n",
              "      <td>fear</td>\n",
              "      <td>(had, shout, younger, brother, wa, alway, afra...</td>\n",
              "      <td>had shout younger brother wa alway afraid call...</td>\n",
              "      <td>[had, shout, younger, brother, wa, alway, afra...</td>\n",
              "      <td>[fear]</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>7516 rows ร 5 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "            0  ...          4\n",
              "0         joy  ...      [joy]\n",
              "1        fear  ...     [fear]\n",
              "2       anger  ...    [anger]\n",
              "3     sadness  ...  [sadness]\n",
              "4     disgust  ...  [disgust]\n",
              "...       ...  ...        ...\n",
              "7511    shame  ...    [shame]\n",
              "7512    shame  ...    [shame]\n",
              "7513     fear  ...     [fear]\n",
              "7514    guilt  ...    [guilt]\n",
              "7515     fear  ...     [fear]\n",
              "\n",
              "[7516 rows x 5 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 65
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GKMtPTkXDPsP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Reads the emotion representative words file\n",
        "def readfile(filename):\n",
        "    f = open(filename,'r')\n",
        "    representative_words = []\n",
        "    for line in f.readlines():\n",
        "        characters = [\"\\n\", \" \", \"\\r\", \"\\t\"]\n",
        "        new = ''.join([i for i in line if not [e for e in characters if e in i]])\n",
        "        representative_words.append(new)\n",
        "    return representative_words"
      ],
      "execution_count": 66,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aAArkaRADS2A",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Makes a list of all words semantically related to an emotion and Stemming\n",
        "def affect_wordlist(words):\n",
        "    affect_words = []\n",
        "    stemmer = PorterStemmer()\n",
        "    for w in words:\n",
        "        w_l = w.lower()\n",
        "        word_stem = stemmer.stem(w_l)\n",
        "        if word_stem not in affect_words:\n",
        "            affect_words.append(word_stem)\n",
        "    return affect_words"
      ],
      "execution_count": 67,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "plcua9poDTw3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Creating an emotion wordnet\n",
        "def emotion_word_set(emotions):\n",
        "    word_set = {}\n",
        "    for e in emotions:\n",
        "        representative_words = readfile(e)\n",
        "        wordlist = affect_wordlist(representative_words)\n",
        "        word_set[e] = wordlist\n",
        "    return word_set"
      ],
      "execution_count": 68,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CDQCb9pME8PV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Emotion Detector - Getting synonyms from wordnet synsets\n",
        "def get_synonyms():\n",
        "    syn = {}\n",
        "    for e in emotion_labels:\n",
        "        jw = wn.synsets(e)\n",
        "        for s in jw:\n",
        "            v = s.name()\n",
        "            try:\n",
        "                syn[e].append(wn.synset(v).lemma_names())\n",
        "            except KeyError:\n",
        "                syn[e] = wn.synset(v).lemma_names()"
      ],
      "execution_count": 69,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IhV4RB9oFCRR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Emotion Detector - Creating training/testing set for Naive Bayes classifier TextBlob -- Not used\n",
        "def create_dataset_textblob(sentences, emotions):\n",
        "    train = []\n",
        "    sen = []\n",
        "    emo = []\n",
        "    for s in sentences:\n",
        "        sen.append(s)\n",
        "    for e in emotions:\n",
        "        emo.append(e)\n",
        "    for i in range(len(sen)):\n",
        "        s = sen[i]\n",
        "        e = emo[i]\n",
        "        train.append((str(s), e))\n",
        "    return train"
      ],
      "execution_count": 70,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bNay6P_NFETn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Testing for Naive Bayes Classifier\n",
        "def testing(cl, test):\n",
        "    for s, e in test:\n",
        "        r = cl.classify(s)\n",
        "        print(s, e, r)\n",
        "        if r == e:\n",
        "            print(\"*\")"
      ],
      "execution_count": 71,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3at0u6ixFGyD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Create dataset for nltk Naive Bayes\n",
        "def create_data(sentence, emotion):\n",
        "    data = []\n",
        "    for i in range(len(sentence)):\n",
        "        sen = []\n",
        "        for s in sentence[i]:\n",
        "            sen.append(str(s))\n",
        "        emo = emotion[i]\n",
        "        data.append((sen, emo))\n",
        "    return data"
      ],
      "execution_count": 72,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AlHE1uawFOWe",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Get all words in dataset\n",
        "def get_words_in_dataset(dataset):\n",
        "    all_words = []\n",
        "    for (words, sentiment) in dataset:\n",
        "        all_words.extend(words)\n",
        "    return all_words"
      ],
      "execution_count": 73,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "shjZdFEfFQx0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Getting frequency dist of words\n",
        "def get_word_features(wordlist):\n",
        "    wordlist = nltk.FreqDist(wordlist)\n",
        "    word_features = wordlist.keys()\n",
        "    return word_features"
      ],
      "execution_count": 74,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FLYLJpeAFTnk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Extacting features\n",
        "def extract_features(document):\n",
        "    document_words = set(document)\n",
        "    features = {}\n",
        "    for word in word_features:\n",
        "        features['contains(%s)' % word] = (word in document_words)\n",
        "    return features"
      ],
      "execution_count": 75,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Imp3wer6FVbc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Create test data\n",
        "def create_test(sentence, emotion):\n",
        "    data = []\n",
        "    sen = []\n",
        "    emo = []\n",
        "    for s in sentence:\n",
        "        sen.append(str(s))\n",
        "    for e in emotion:\n",
        "        emo.append(e)\n",
        "    for i in range(len(sen)):\n",
        "        temp = []\n",
        "        temp.append(sen[i])\n",
        "        temp.append(emo[i])\n",
        "        data.append(temp)\n",
        "    return data"
      ],
      "execution_count": 76,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4AkMOgu9FXjB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Classifier\n",
        "def classify_dataset(data):\n",
        "    return \\\n",
        "        classifier.classify(extract_features(nltk.word_tokenize(data)))"
      ],
      "execution_count": 78,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OUIYmNJCFcoB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Get accuracy\n",
        "def get_accuracy(test_data, classifier):\n",
        "    total = accuracy = float(len(test_data))\n",
        "    for data in test_data:\n",
        "        if classify_dataset(data[0]) != data[1]:\n",
        "#             print data, classify_dataset(data[0]), data[1]\n",
        "            accuracy -= 1\n",
        "    print('Total accuracy: %f%% (%d/20).' % (accuracy / total * 100, accuracy))\n",
        "    final = accuracy / total * 100\n",
        "    return final"
      ],
      "execution_count": 80,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gWwe8ChfFfLM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Create training and testing data\n",
        "sen = c[3]\n",
        "emo = c[0]\n",
        "l = len(c[3])\n",
        "limit = (9*l)//10\n",
        "sente = c[2]\n",
        "Data = create_data(sen[:limit], emo[:limit])\n",
        "test_data = create_test(sente[limit:], emo[limit:])"
      ],
      "execution_count": 81,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9oogVUUiFicg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# extract the word features out from the training data\n",
        "word_features = get_word_features(\\\n",
        "                    get_words_in_dataset(Data))"
      ],
      "execution_count": 82,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e5Z-lvJ6FkW5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# get the training set and train the Naive Bayes Classifier\n",
        "training_set = nltk.classify.util.apply_features(extract_features, Data)\n",
        "classifier = NaiveBayesClassifier.train(training_set)"
      ],
      "execution_count": 83,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nDGi3qU6GQwu",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "22733138-8cc0-4fe5-ff60-8a96333211fb"
      },
      "source": [
        "Naive_accu = get_accuracy(test_data, classifier)"
      ],
      "execution_count": 84,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Total accuracy: 63.164894% (475/20).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_OVStt--IK2d",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "d83e4727-2baa-4021-ff7a-81509b069c91"
      },
      "source": [
        "print(\"Accuracy using Naive Bayes Component  \", Naive_accu, \"%\")"
      ],
      "execution_count": 85,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy using Naive Bayes Component   63.16489361702128 %\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}